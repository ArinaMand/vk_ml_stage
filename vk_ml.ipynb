{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Должно сказать, что предоставленный датасет вызвал у меня некоторые вопросы. Дело в том, что во всех статьях на тему ранжирования подразумевается, что результаты запроса \"отсортированы\" в порядке релевантности. Т.к. предоставленный датасет не содержал подходящего под описание поля, возникло предположение, что принятый порядок записей для запроса и является самым релевантным. Однако в таком случае непонятно, как работать с тестовыми данными, которые сами собой представляют релевантно упорядоченные данные.\n",
        "\n",
        "В связи с выше сказанным было принято решение рассматривать параметр target как бинарный критерий релевантности данных.\n",
        "\n",
        "Для решения задачи ранжирования достаточно широкое применение имеет ансамбль деревьев. Однако в нашем случае бинарного ранжирования было принято решения обойтись одним деревом, и полученное значение метрики NDCG показало достаточность данного метода.\n"
      ],
      "metadata": {
        "id": "vF9bDflU_xUK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PenG23YTPJyN"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.metrics import ndcg_score"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('train_df.csv')\n",
        "df_test = pd.read_csv('test_df.csv')"
      ],
      "metadata": {
        "id": "mD5NjfJbQS-S"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_x = df.loc[:, 'feature_0':'feature_78']\n",
        "train_y = df['target']\n",
        "\n",
        "test_x = df_test.loc[:, 'feature_0':'feature_78']\n",
        "test_y = df_test['target']"
      ],
      "metadata": {
        "id": "zUE2vDFXgRVg"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "clf = DecisionTreeClassifier(random_state=0)\n",
        "clf.fit(df, train_y)\n",
        "\n",
        "answer = clf.predict(df_test)"
      ],
      "metadata": {
        "id": "WBwE5E163P72"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import ndcg_score\n",
        "\n",
        "ndcg_score([test_y], [answer])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wtOt5aVF-iKH",
        "outputId": "46b2470d-7107-4ba9-daf4-37f87dd3f5bc"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9999999999999998"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    }
  ]
}